|논문명|단일 카메라를 이용한 3차원 공간 정보 생성|
|-|-|
|저자(소속)|권오영 (연세대)|
|학회/년도| 한국정보통신학회논문지 2015, [논문](https://www.mendeley.com/viewer/?fileId=415af95d-a4d9-dc65-1a22-028b55c43eaa&documentId=a7a30509-e5f0-3d6d-9d5d-d4d1b02b6632), [Download](http://koreascience.or.kr/article/ArticleFullRecord.jsp?cn=HOJBC0_2015_v19n12_2943)|
|키워드|단일 카메라, 연속된 2장의 사진, SIFT[5] 특징점, 삼각측량|
|참고||
|코드||


# 단일 카메라를 이용한 3차원 공간 정보 생성


![](https://i.imgur.com/z8kpn1l.png)

## Ⅱ. 3차원 복원 과정

### 2.1. 수행과정

3차원 복원 과정은 그림 1과 같이 이미지를 가져와 영상의 **특징점**을 찾아 이를 토대로 매칭 과정을 거치고 기본행렬을 계산하여 **삼각측량**을 수행하는 과정으로 이루어진다. 

본 연구에서 수행한 단일 카메라를 이용한 방법도 이와 같은 과정으로 진행되나 빠른 연산을 위해 카메라로부터 얻은 시간적으로 차이가 있는 이미지 2장을 이용하며 블랙박스에 주로 사용되는 어안렌즈를 복원하는과정과 불필요한 데이터를 삭제하는 과정이 추가된다. 

### 2.2. 카메라 내부 파라미터 측정

카메라로부터 얻은 2차원 영상과 3차원 정보간에 동일한 위치를 구하기 위해서는 사용된 렌즈, 렌즈와 영상센서와의 거리, 렌즈와 영상 센서가 이루는 각 등의 카메라 내부적인 요인을 제거해야만 정확한 계산이 가능하다. 

카메라 내부 파라미터[2]는 측정하는 여러 방법이있지만 본 연구에서는 ‘gml c++ camera calibrationtoolbox’ 툴을 이용하여 내부 파라미터를 측정하였다[3].

이 툴은 여러 각도에서 촬영된 패턴을 이용하 카메라 내부 파라미터를 측정한다. 

내부 파라미터 측정에 앞서 차량용 카메라의 경우 일반적으로 높은 시야각을 위해 어안(fisheye) 렌즈를 사용하기 때문에 차량용 카메라에 획득되는 영상 정보가 왜곡되어 들어오기 때문에 이러한왜곡된 정보를 보정해주는 과정이 필요하다. 

왜곡보정과정은 카메라 내부 파라미터에 의해 보정된 픽셀을 왜곡영상의 대응되는 픽셀로 채워 넣는 것이다[4].

### 2.3. 특징점 추출

![](https://i.imgur.com/3hLhF9S.png)

영상의 특징점은 다양한 방법들이 소개된다. 

그 중본 연구에서는 **SIFT[5] 특징점**을 사용하였는데 이는 모든 이미지 프레임에서 추출의 수가 많고 일정하여, 3차원 공간 복원 시 유리하기 때문이다. 

SIFT는 영상에서 코너점 등, 식별이 용이한 특징점 들을 선택한 후에 각특징점을 중심으로 한 로컬 패치(local patch)에 대해 아래 그림과 같은 특징 벡터를 추출한 것을 말한다. 

> SIFT는 이미지 회전, 스케일링, 이동, 부분 조명 변화 및 투영 변환에 불변인 특성을 지니고 있다. 


### 2.4. 기본 행렬


SIFT descriptor를 이용하여 두 이미지간의 매칭 쌍을 찾을 수 있고, 매칭 되는 점의 위치 값을 통해 기본행렬(Fundamental Matrix)[6]을 구할 수 있다. 

이는 카메라 파라미터를 포함한 두 이미지 실제 픽셀 좌표 사이의 기하학전 관계를 표현한다. 

매칭 후 연산속도 증가를 위해 RANSAC[7]을 통해 불필요한 데이터를 걸러낸다. 

그림 3은 두 이미지 사이의 매칭점을 선으로연결하여 나타낸 것이다.

![](https://i.imgur.com/EWFaxdA.png)


### 2.5. Triangulation

![](https://i.imgur.com/TmgLikh.png)

Triangulation[8,9]은 식 1에 의해 두 영상 평면 사이의 기하학적 관계가 주어지고(즉, E 또는 F가 주어지고)두 영상 평면상의 매칭쌍 p, p'이 주어지면 이로부터 원래의 3차원 공간좌표 P를 결정할 수 있다는 것을 말한다.

---

|논문명|단일 카메라를 이용한 보행자의 높이 및 위치 추정 기법|
|-|-|
|저자(소속)|이석한 (중앙대)|
|학회/년도| 2008, [논문](http://insight.dbpia.co.kr/article/related.do?nodeId=NODE00997199)|
|키워드|단일 카메라|
|참고||
|코드||

기존 방법 
- 영상의 2차원 좌표계 상의 한 점이 3차원 공간으로 역사영(back-projection) 될 때 이에 대한 스케일 값이 정의 되지 않는 특성이 있다
- 따라서 일반적인 단일 영상 기반의 3차원 정보 복원 기법은 영상 내에 존재하는 환경 구조물들의 **수직-수평 관계, 또는 소실점 및 소실선** 등 과 같은 기하학적인 **단서들을 병용**함으로써 구현된다

제안 방법 
- 기준 점을 이용

---

|논문명|단일 카메라 영상에서의 보행자 거리 추정|
|-|-|
|저자(소속)|전태재 (연대)|
|학회/년도| 2014, [논문](http://insight.dbpia.co.kr/article/related.do?nodeId=NODE02438677)|
|키워드|단일 카메라|
|참고||
|코드||

보행자 위치 정보와 영상에서의 소실점 정보를 이용하여 카메라와 보행자 간 거리 정보를 추정

![](https://i.imgur.com/YKvUCwC.png)

1. 보행자 검출 : HOG/SVM

2. 보행자의 발 영역 :HOG/SVM, 위치 정확도가 보행자 거리 추정에 영향을 미치므로 

3. 보행자의 거리 추정
    - 보행자의 거리를 추정하기 위해 카메라 장착 위치가 지면에 평행하고 취득된 영상에 왜곡이 없다고 가정한
    다. 
    - 우선 영상에서 소실점의 위치를 구하고, 카메라 칼리브레이션을 수행하여 초점거리를 구한다
    - 초점거리, 영상에서 소실점과 보행자의 발 사이의 y방향 픽셀 수, 실제 거리, 영상을 찍은 카메라의 실제 높이로 비례식을 세워 보행자까지의 거리를 추정 $$\frac{F}{P} = \frac{D}{C}$$


결과 : 실험결과 10m이내의 거리에서는 오차율 약 7%의 성능으로 거리 추정이 가능

---

|논문명|단일 카메라를 이용한 차량 검출 및 거리추정|
|-|-|
|저자(소속)|이창화 (경북대)|
|학회/년도| 2016, [논문](http://www.dbpia.co.kr/Journal/ArticleDetail/NODE07082761)|
|키워드|단일 카메라|
|참고||
|코드||

- 차량 검출/검증 : Haar 특징과 색공간을 활용한 **후미등 검출**, HOG(Higstogram of
Oriented Gradient) 특징을 사용하여 차량 임을 검증

- 거리 추정 : **검출된 차량의 너비**와 **실제 차량의 폭 사이**의 **비례관계**를 통해 예측

![](https://i.imgur.com/v8ltuCr.png)

영상평면의 차 폭을 w, 초점거리를 f,평균 차량의 폭을 W, 카메라와 차량의 거리를 D 라 하고D 가 충분히 크다고 가정 한다면 W:D=w:f 의 식이성립한다
